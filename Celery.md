# Celery ã«ã¤ã„ã¦

Celeryã¯ã€Pythonã§æ›¸ã‹ã‚ŒãŸ**åˆ†æ•£ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼**ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ä»Šå›ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚‚é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¦ã„ã¾ã™ã€‚

## ğŸ”„ Celeryã¨ã¯

**Celery**ã¯ã€æ™‚é–“ã®ã‹ã‹ã‚‹å‡¦ç†ã‚„é‡ã„å‡¦ç†ã‚’**ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰**ã§éåŒæœŸå®Ÿè¡Œã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚

### åŸºæœ¬çš„ãªä»•çµ„ã¿

```
[Webã‚¢ãƒ—ãƒª] â†’ [ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ] â†’ [Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ãŒå‡¦ç†] â†’ [çµæœã‚’ä¿å­˜]
     â†“                                      â†‘
[ã™ãã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹]                    [ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ]
```

## ğŸ“‹ ä»Šå›ã®ã‚¢ãƒ—ãƒªã§ã®Celeryã®å½¹å‰²

### 1. **ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã®éåŒæœŸå®Ÿè¡Œ**
```python
# scraper/tasks.py
@shared_task
def scrape_target(target_id):
    """æŒ‡å®šã•ã‚ŒãŸã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹ã‚¿ã‚¹ã‚¯"""
    # æ™‚é–“ã®ã‹ã‹ã‚‹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç†
    target = ScrapingTarget.objects.get(id=target_id)
    # ... ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ ...
```

### 2. **ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã®å‘ä¸Š**
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™
- ã™ãã«ã€Œé–‹å§‹ã—ã¾ã—ãŸã€ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹
- å®Ÿéš›ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã¯ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ä»–ã®æ“ä½œã‚’ç¶šã‘ã‚‰ã‚Œã‚‹

### 3. **ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆã§ã®ä½ç½®ã¥ã‘**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Django    â”‚â”€â”€â”€â–¶â”‚    Redis    â”‚â”€â”€â”€â–¶â”‚   Celery    â”‚
â”‚ Webã‚¢ãƒ—ãƒª    â”‚    â”‚ (ãƒ–ãƒ­ãƒ¼ã‚«ãƒ¼) â”‚    â”‚ ãƒ¯ãƒ¼ã‚«ãƒ¼     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                      â”‚
        â–¼                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°â”‚
â”‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ â”‚                    â”‚    å®Ÿè¡Œ     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Celeryã®ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

### 1. **ãƒ–ãƒ­ãƒ¼ã‚«ãƒ¼ (Broker)**
- **Redis** ã‚’ä½¿ç”¨
- ã‚¿ã‚¹ã‚¯ã®ã‚­ãƒ¥ãƒ¼ã‚’ç®¡ç†
- Djangoã‚¢ãƒ—ãƒªã¨Celeryãƒ¯ãƒ¼ã‚«ãƒ¼é–“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é…ä¿¡

### 2. **ãƒ¯ãƒ¼ã‚«ãƒ¼ (Worker)**
- å®Ÿéš›ã«ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹
- è¤‡æ•°ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½
- ```bash
  celery -A scraping_project worker --loglevel=info
  ```

### 3. **ã‚¿ã‚¹ã‚¯ (Task)**
- `@shared_task` ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã§å®šç¾©
- éåŒæœŸã§å®Ÿè¡Œã•ã‚Œã‚‹é–¢æ•°

## ğŸ’¡ ä»Šå›ã®ã‚¢ãƒ—ãƒªã§ã®å…·ä½“çš„ãªä½¿ç”¨ä¾‹

### ã‚¿ã‚¹ã‚¯ã®å®šç¾©
```python
# scraper/tasks.py
@shared_task
def scrape_target(target_id):
    """å€‹åˆ¥ã‚µã‚¤ãƒˆã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
    # 1. ã‚¸ãƒ§ãƒ–ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆ
    # 2. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ
    # 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
    # 4. ã‚¸ãƒ§ãƒ–å®Œäº†è¨˜éŒ²

@shared_task
def scrape_all_active_targets():
    """å…¨ã‚µã‚¤ãƒˆã®ä¸€æ‹¬ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""

@shared_task
def cleanup_old_data(days=30):
    """å¤ã„ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
```

### ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œ
```python
# scraper/views.py
def start_scraping(request, target_id):
    # ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ï¼ˆã™ãã«è¿”ã‚‹ï¼‰
    result = scrape_target.delay(target_id)
    messages.success(request, f'ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚Job ID: {result.id}')
    return redirect('scraper:dashboard')
```

## ğŸ¯ Celeryã‚’ä½¿ã†ç†ç”±

### 1. **ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ€§ã®å‘ä¸Š**
- ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã¯æ•°ç§’ã€œæ•°åˆ†ã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚‹
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å¾…ãŸã›ãªã„

### 2. **ã‚·ã‚¹ãƒ†ãƒ ã®å®‰å®šæ€§**
- é‡ã„å‡¦ç†ã§Webã‚µãƒ¼ãƒãƒ¼ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œãªã„
- è¤‡æ•°ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’åŒæ™‚å®Ÿè¡Œå¯èƒ½

### 3. **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**
- ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’è¤‡æ•°å°ã®ã‚µãƒ¼ãƒãƒ¼ã«åˆ†æ•£å¯èƒ½
- å‡¦ç†èƒ½åŠ›ã‚’ç°¡å˜ã«æ‹¡å¼µ

### 4. **ã‚¨ãƒ©ãƒ¼å‡¦ç†**
- ã‚¿ã‚¹ã‚¯ãŒå¤±æ•—ã—ã¦ã‚‚è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤
- ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ç®¡ç†

## ğŸ“Š ã‚¸ãƒ§ãƒ–ç®¡ç†æ©Ÿèƒ½

ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã€Celeryã‚¿ã‚¹ã‚¯ã®çŠ¶æ…‹ã‚’è¿½è·¡ï¼š

```python
class ScrapingJob(models.Model):
    STATUS_CHOICES = [
        ('pending', 'å¾…æ©Ÿä¸­'),
        ('running', 'å®Ÿè¡Œä¸­'), 
        ('completed', 'å®Œäº†'),
        ('failed', 'å¤±æ•—'),
    ]
    
    target = models.ForeignKey(ScrapingTarget, on_delete=models.CASCADE)
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default='pending')
    started_at = models.DateTimeField(null=True, blank=True)
    completed_at = models.DateTimeField(null=True, blank=True)
    error_message = models.TextField(blank=True)
    items_scraped = models.IntegerField(default=0)
```

## ğŸ”§ è¨­å®šä¾‹

### Djangoè¨­å®š (settings.py)
```python
# Celery Configuration
REDIS_URL = os.getenv('REDIS_URL', 'redis://localhost:6379/0')
CELERY_BROKER_URL = REDIS_URL
CELERY_RESULT_BACKEND = REDIS_URL
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
CELERY_TIMEZONE = TIME_ZONE
```

### CeleryåˆæœŸåŒ– (scraping_project/celery.py)
```python
import os
from celery import Celery

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'scraping_project.settings')

app = Celery('scraping_project')
app.config_from_object('django.conf:settings', namespace='CELERY')
app.autodiscover_tasks()
```

### Docker Composeè¨­å®š
```yaml
celery:
  build: .
  command: celery -A scraping_project worker --loglevel=info
  depends_on:
    - db
    - redis
  environment:
    - DEBUG=1
    - DATABASE_URL=postgresql://scraping_user:scraping_password@db:5432/scraping_db
    - REDIS_URL=redis://redis:6379/0
```

## ğŸš€ Celeryã‚³ãƒãƒ³ãƒ‰

### ãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•
```bash
# é–‹ç™ºç’°å¢ƒ
celery -A scraping_project worker --loglevel=info

# Dockerç’°å¢ƒ
docker-compose exec celery celery -A scraping_project worker --loglevel=info
```

### ã‚¿ã‚¹ã‚¯ç›£è¦–
```bash
# Celeryç›£è¦–ãƒ„ãƒ¼ãƒ«
celery -A scraping_project flower

# ãƒ¯ãƒ¼ã‚«ãƒ¼çŠ¶æ…‹ç¢ºèª
celery -A scraping_project inspect active
```

### å®šæœŸå®Ÿè¡Œè¨­å®š (Celery Beat)
```python
# settings.py
from celery.schedules import crontab

CELERY_BEAT_SCHEDULE = {
    'scrape-all-sites-daily': {
        'task': 'scraper.tasks.scrape_all_active_targets',
        'schedule': crontab(hour=0, minute=0),  # æ¯æ—¥åˆå‰0æ™‚
    },
    'cleanup-old-data-weekly': {
        'task': 'scraper.tasks.cleanup_old_data',
        'schedule': crontab(hour=2, minute=0, day_of_week=1),  # æ¯é€±æœˆæ›œæ—¥åˆå‰2æ™‚
        'args': (30,)  # 30æ—¥ä»¥ä¸Šå¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
    },
}
```

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

1. **Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ãŒèµ·å‹•ã—ãªã„**
   ```bash
   # Redisæ¥ç¶šç¢ºèª
   docker-compose logs redis
   
   # Celeryãƒ­ã‚°ç¢ºèª
   docker-compose logs celery
   ```

2. **ã‚¿ã‚¹ã‚¯ãŒå®Ÿè¡Œã•ã‚Œãªã„**
   ```bash
   # ãƒ¯ãƒ¼ã‚«ãƒ¼ã®çŠ¶æ…‹ç¢ºèª
   celery -A scraping_project inspect active
   
   # ã‚­ãƒ¥ãƒ¼ã®ç¢ºèª
   celery -A scraping_project inspect reserved
   ```

3. **ãƒ¡ãƒ¢ãƒªä¸è¶³**
   ```python
   # ã‚¿ã‚¹ã‚¯ã§ã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
   @shared_task
   def scrape_target(target_id):
       try:
           # å‡¦ç†
           pass
       finally:
           # ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
           gc.collect()
   ```

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 1. **ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã®èª¿æ•´**
```bash
# CPUã‚³ã‚¢æ•°ã«åŸºã¥ã„ã¦èª¿æ•´
celery -A scraping_project worker --concurrency=4
```

### 2. **ã‚¿ã‚¹ã‚¯ã®å„ªå…ˆåº¦è¨­å®š**
```python
@shared_task(priority=1)  # é«˜å„ªå…ˆåº¦
def urgent_scraping_task():
    pass

@shared_task(priority=9)  # ä½å„ªå…ˆåº¦
def cleanup_task():
    pass
```

### 3. **ãƒãƒƒãƒå‡¦ç†**
```python
@shared_task
def batch_scrape_targets(target_ids):
    """è¤‡æ•°ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’ã¾ã¨ã‚ã¦å‡¦ç†"""
    for target_id in target_ids:
        scrape_single_target(target_id)
```

## ğŸ‰ ã¾ã¨ã‚

Celeryã«ã‚ˆã‚Šã€ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ï¼š

- âœ… **é«˜æ€§èƒ½** - ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ã«ã‚ˆã‚Šå¿œç­”æ€§å‘ä¸Š
- âœ… **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«** - è¤‡æ•°ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ã®ä¸¦åˆ—å‡¦ç†
- âœ… **ä¿¡é ¼æ€§** - ã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½
- âœ… **ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼** - å¾…æ©Ÿæ™‚é–“ãªã—ã®æ“ä½œ

ã“ã‚Œã‚‰ã®ç‰¹å¾´ã«ã‚ˆã‚Šã€ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒ¬ãƒ™ãƒ«ã®Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ãŒå®Ÿç¾ã•ã‚Œã¦ã„ã¾ã™ï¼ 